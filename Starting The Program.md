### Please see 'Spark config.md' and 'Starting the Container.md' before attempting
### Ensure Docker Containers are built and running
- navigate to working directory
- start producer in a seperate window >> python run_prod.py/run_prod_m.py for single/multiple respectively. 
- Optional: python_run_kafka_data.py to verify data is being pushed. 
- run spark job: run_spark_plotly.py/run_spark_plotly_m.py